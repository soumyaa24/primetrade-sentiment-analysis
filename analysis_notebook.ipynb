{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# ðŸ“Š Trader Performance vs Market Sentiment\n",
                "## Primetrade.ai â€” Data Science / Analytics Intern Â· Round-0 Assignment\n\n",
                "**Author:** Soumya Jha &nbsp;|&nbsp; **Date:** Feb 2026\n\n",
                "---\n",
                "### Objective\n",
                "Analyze how Bitcoin market sentiment (Fear/Greed Index) relates to trader behavior and performance on Hyperliquid. Uncover patterns that inform smarter trading strategies.\n\n",
                "### Datasets\n",
                "1. **Bitcoin Fear/Greed Index** â€” daily sentiment classification (Fear â†’ Extreme Greed)\n",
                "2. **Hyperliquid Trader Data** â€” 211,224 historical trade records across 32 accounts\n\n",
                "### Table of Contents\n",
                "- [1. Setup & Imports](#setup)\n",
                "- [Part A â€” Data Preparation](#part-a)\n",
                "- [Part B â€” Analysis](#part-b)\n",
                "- [Part C â€” Actionable Output](#part-c)\n",
                "- [Bonus â€” Predictive Model](#bonus-model)\n",
                "- [Bonus â€” Behavioral Clustering](#bonus-cluster)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Setup & Imports <a id='setup'></a>"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os, warnings\n",
                "warnings.filterwarnings('ignore')\n\n",
                "import numpy as np\n",
                "import pandas as pd\n",
                "import matplotlib.pyplot as plt\n",
                "import matplotlib.patches as mpatches\n",
                "import seaborn as sns\n",
                "from scipy import stats\n",
                "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
                "from sklearn.cluster import KMeans\n",
                "from sklearn.ensemble import RandomForestClassifier\n",
                "from sklearn.model_selection import train_test_split, cross_val_score\n",
                "from sklearn.metrics import classification_report, roc_auc_score\n\n",
                "plt.style.use('dark_background')\n",
                "plt.rcParams.update({'figure.facecolor':'#0d1117','axes.facecolor':'#161b22',\n",
                "                     'axes.edgecolor':'#30363d','axes.titlecolor':'#58a6ff','figure.dpi':120})\n",
                "FEAR_COLOR, GREED_COLOR = '#ff453a', '#30d158'\n\n",
                "os.makedirs('charts', exist_ok=True)\n",
                "os.makedirs('outputs', exist_ok=True)\n",
                "print('Setup complete.')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Part A â€” Data Preparation <a id='part-a'></a>\n",
                "### A1. Load Both Datasets & Document\n",
                "> We document: number of rows/columns, missing values, and duplicates for each dataset."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "fg_raw = pd.read_csv('data/fear_greed.csv')\n",
                "td_raw = pd.read_csv('data/trader_data.csv')\n\n",
                "print('='*55)\n",
                "print('DATASET 1 â€” Bitcoin Fear/Greed Index')\n",
                "print('='*55)\n",
                "print(f'Shape     : {fg_raw.shape[0]:,} rows x {fg_raw.shape[1]} columns')\n",
                "print(f'Columns   : {list(fg_raw.columns)}')\n",
                "print('\\nFirst 5 rows:')\n",
                "display(fg_raw.head())\n",
                "print('\\nMissing values:')\n",
                "display(fg_raw.isnull().sum().rename('Missing'))\n",
                "print(f'Duplicates: {fg_raw.duplicated().sum()}')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print('='*55)\n",
                "print('DATASET 2 â€” Hyperliquid Trader Data')\n",
                "print('='*55)\n",
                "print(f'Shape     : {td_raw.shape[0]:,} rows x {td_raw.shape[1]} columns')\n",
                "print(f'Columns   : {list(td_raw.columns)}')\n",
                "print('\\nFirst 5 rows:')\n",
                "display(td_raw.head())\n",
                "print('\\nData types:')\n",
                "display(td_raw.dtypes.rename('dtype'))\n",
                "print('\\nMissing values:')\n",
                "display(td_raw.isnull().sum().rename('Missing'))\n",
                "print(f'Duplicates: {td_raw.duplicated().sum()}')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Summary:** Both datasets are remarkably clean â€” zero missing values and zero duplicates. No imputation needed. We can proceed directly to timestamp alignment.\n\n",
                "| Dataset | Rows | Cols | Missing | Duplicates |\n",
                "|---------|------|------|---------|------------|\n",
                "| Fear/Greed Index | 2,644 | 4 | 0 | 0 |\n",
                "| Trader Data | 211,224 | 16 | 0 | 0 |"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### A2. Timestamp Conversion & Date Alignment\n",
                "> Key finding: The `Timestamp` (numeric) column has only **7 unique values** â€” it is truncated/rounded and unusable for date extraction. We use `Timestamp IST` (`dd-mm-yyyy hh:mm`) instead, which parses correctly to 480 unique trading dates."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Check numeric Timestamp quality\n",
                "td_raw['Timestamp_num'] = pd.to_numeric(td_raw['Timestamp'], errors='coerce')\n",
                "print(f'Numeric Timestamp unique values: {td_raw[\"Timestamp_num\"].nunique()} <- nearly useless!')\n",
                "print(f'Timestamp IST unique values    : {td_raw[\"Timestamp IST\"].nunique()} <- correct')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Clean Fear/Greed\n",
                "fg = fg_raw.copy()\n",
                "fg['classification'] = fg['classification'].str.strip()\n",
                "fg['sentiment'] = fg['classification'].apply(\n",
                "    lambda x: 'Fear' if 'Fear' in str(x) else ('Greed' if 'Greed' in str(x) else 'Neutral'))\n",
                "fg['date'] = pd.to_datetime(fg['date'])\n",
                "fg = fg[fg['sentiment'].isin(['Fear','Greed'])].drop_duplicates('date').sort_values('date').reset_index(drop=True)\n\n",
                "print('Fear/Greed cleaned:')\n",
                "print(f'  Date range : {fg.date.min().date()} -> {fg.date.max().date()}')\n",
                "display(fg['sentiment'].value_counts().rename('Days'))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Clean Trader Data â€” use Timestamp IST with dayfirst=True (dd-mm-yyyy)\n",
                "td = td_raw.copy()\n",
                "td['datetime'] = pd.to_datetime(td['Timestamp IST'], dayfirst=True, errors='coerce')\n",
                "td = td.dropna(subset=['datetime'])\n",
                "td['date'] = td['datetime'].dt.normalize()\n\n",
                "for col in ['Execution Price','Size Tokens','Size USD','Closed PnL','Start Position','Fee']:\n",
                "    td[col] = pd.to_numeric(td[col], errors='coerce')\n\n",
                "td_trades = td[td['Closed PnL'].notna()].copy()\n\n",
                "print('Trader data cleaned:')\n",
                "print(f'  Date range      : {td_trades.date.min().date()} -> {td_trades.date.max().date()}')\n",
                "print(f'  Unique dates    : {td_trades.date.nunique()}')\n",
                "print(f'  Unique accounts : {td_trades.Account.nunique()}')\n",
                "print(f'  Trade rows w PnL: {len(td_trades):,}')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Inner join â€” align trader data with sentiment by date\n",
                "merged = td_trades.merge(fg[['date','sentiment','value','classification']], on='date', how='inner')\n\n",
                "print(f'Rows after inner merge   : {len(merged):,}')\n",
                "print(f'Date overlap             : {merged.date.min().date()} -> {merged.date.max().date()}')\n",
                "print(f'Sentiment distribution:')\n",
                "display(merged['sentiment'].value_counts().rename('Trades'))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### A3. Create Key Metrics\n",
                "We build the following metrics at daily Ã— account level:\n",
                "- **daily PnL** â€” sum of Closed PnL per account per day\n",
                "- **win rate** â€” fraction of profitable trades\n",
                "- **average trade size** (USD)\n",
                "- **leverage proxy** â€” |Size USD| / |Start Position| (Hyperliquid doesn't store raw leverage)\n",
                "- **number of trades per day**\n",
                "- **long/short ratio** â€” BUY count / SELL count"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "merged['is_win']    = (merged['Closed PnL'] > 0).astype(int)\n",
                "merged['lev_proxy'] = np.where(\n",
                "    merged['Start Position'].abs() > 0,\n",
                "    merged['Size USD'].abs() / (merged['Start Position'].abs() + 1e-9), np.nan)\n\n",
                "# Daily per-account aggregation\n",
                "daily = (merged.groupby(['Account','date','sentiment'])\n",
                "               .agg(daily_pnl    = ('Closed PnL','sum'),\n",
                "                    n_trades     = ('Closed PnL','count'),\n",
                "                    win_count    = ('is_win','sum'),\n",
                "                    avg_size_usd = ('Size USD','mean'))\n",
                "               .reset_index())\n",
                "daily['win_rate'] = daily['win_count'] / daily['n_trades']\n\n",
                "# Long/Short ratio\n",
                "sides = (merged.groupby(['Account','date','sentiment'])\n",
                "               .apply(lambda g: (g['Side']=='BUY').sum() / max((g['Side']=='SELL').sum(),1))\n",
                "               .reset_index(name='long_short_ratio'))\n",
                "daily = daily.merge(sides, on=['Account','date','sentiment'], how='left')\n\n",
                "# Leverage proxy per day\n",
                "lev_d = merged.groupby(['Account','date'])['lev_proxy'].median().reset_index(name='median_lev_proxy')\n",
                "daily = daily.merge(lev_d, on=['Account','date'], how='left')\n\n",
                "print(f'Daily account-level rows : {len(daily):,}')\n",
                "print(f'Unique dates             : {daily.date.nunique()}')\n",
                "print(f'Unique accounts          : {daily.Account.nunique()}')\n",
                "print('\\nSample daily metrics:')\n",
                "display(daily.head(8))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Summary table by sentiment\n",
                "summary = daily.groupby('sentiment').agg(\n",
                "    days         = ('date','nunique'),\n",
                "    acct_day_rows= ('daily_pnl','count'),\n",
                "    mean_pnl     = ('daily_pnl','mean'),\n",
                "    median_pnl   = ('daily_pnl','median'),\n",
                "    mean_win_rate= ('win_rate','mean'),\n",
                "    mean_trades  = ('n_trades','mean'),\n",
                "    mean_size_usd= ('avg_size_usd','mean'),\n",
                "    mean_ls_ratio= ('long_short_ratio','mean')\n",
                ").round(2)\n",
                "print('Key Metrics Summary by Sentiment:')\n",
                "display(summary)\n\n",
                "# Save\n",
                "daily.to_csv('outputs/daily_account_metrics.csv', index=False)\n",
                "print('\\nSaved: outputs/daily_account_metrics.csv')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Part B â€” Analysis <a id='part-b'></a>\n",
                "### B1. Does performance differ between Fear vs Greed days?\n",
                "> We compare daily PnL per account, win rate, and a drawdown proxy across the two sentiment regimes using the Mann-Whitney U test (non-parametric, no normality assumption)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "fear_d  = daily[daily['sentiment']=='Fear']\n",
                "greed_d = daily[daily['sentiment']=='Greed']\n\n",
                "pnl_fear  = fear_d['daily_pnl'].dropna()\n",
                "pnl_greed = greed_d['daily_pnl'].dropna()\n",
                "wr_fear   = fear_d['win_rate'].dropna()\n",
                "wr_greed  = greed_d['win_rate'].dropna()\n\n",
                "_, p_pnl = stats.mannwhitneyu(pnl_fear, pnl_greed, alternative='two-sided')\n",
                "_, p_wr  = stats.mannwhitneyu(wr_fear,  wr_greed,  alternative='two-sided')\n\n",
                "comparison = pd.DataFrame({\n",
                "    'Metric'      : ['Mean Daily PnL','Median Daily PnL','Std Daily PnL','Win Rate (mean)','MW p-value'],\n",
                "    'Fear'        : [f'${pnl_fear.mean():,.2f}',f'${pnl_fear.median():,.2f}',\n",
                "                     f'${pnl_fear.std():,.2f}',f'{wr_fear.mean():.3f}',f'{p_pnl:.4f}'],\n",
                "    'Greed'       : [f'${pnl_greed.mean():,.2f}',f'${pnl_greed.median():,.2f}',\n",
                "                     f'${pnl_greed.std():,.2f}',f'{wr_greed.mean():.3f}',f'{p_wr:.4f}'],\n",
                "    'Significant' : ['Yes (p<0.10)' if p_pnl<0.10 else 'No','','','',\n",
                "                     'Yes' if p_wr<0.05 else 'No']\n",
                "})\n",
                "display(comparison)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Drawdown proxy\n",
                "def max_drawdown(series):\n",
                "    cs = series.cumsum()\n",
                "    return (cs - cs.cummax()).min()\n\n",
                "dd_fear  = fear_d.groupby('Account')['daily_pnl'].apply(max_drawdown)\n",
                "dd_greed = greed_d.groupby('Account')['daily_pnl'].apply(max_drawdown)\n",
                "print(f'Drawdown proxy (avg) â€” Fear : ${dd_fear.mean():,.2f}')\n",
                "print(f'Drawdown proxy (avg) â€” Greed: ${dd_greed.mean():,.2f}')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# CHART 1: PnL Distribution\n",
                "clip = max(abs(pnl_fear.quantile(0.95)), abs(pnl_greed.quantile(0.95))) * 1.5\n",
                "fig, axes = plt.subplots(1, 2, figsize=(14,5))\n",
                "fig.suptitle('Chart 1 â€” Daily PnL Distribution: Fear vs Greed', fontsize=14, fontweight='bold', color='#58a6ff')\n\n",
                "axes[0].hist(pnl_fear.clip(-clip,clip),  bins=60, color=FEAR_COLOR,  alpha=0.75, label='Fear')\n",
                "axes[0].hist(pnl_greed.clip(-clip,clip), bins=60, color=GREED_COLOR, alpha=0.6,  label='Greed')\n",
                "axes[0].axvline(pnl_fear.median(),  color=FEAR_COLOR,  ls='--', lw=1.5, label=f'Fear median={pnl_fear.median():.0f}')\n",
                "axes[0].axvline(pnl_greed.median(), color=GREED_COLOR, ls='--', lw=1.5, label=f'Greed median={pnl_greed.median():.0f}')\n",
                "axes[0].set_xlabel('Daily PnL (USD)'); axes[0].set_ylabel('Frequency')\n",
                "axes[0].set_title('Histogram'); axes[0].legend(fontsize=8); axes[0].grid(alpha=0.3)\n\n",
                "bp = axes[1].boxplot([pnl_fear.clip(-clip,clip), pnl_greed.clip(-clip,clip)],\n",
                "                     patch_artist=True, labels=['Fear','Greed'],\n",
                "                     medianprops=dict(color='white', linewidth=2))\n",
                "for patch, c in zip(bp['boxes'], [FEAR_COLOR, GREED_COLOR]):\n",
                "    patch.set_facecolor(c); patch.set_alpha(0.7)\n",
                "axes[1].set_ylabel('Daily PnL (USD)'); axes[1].set_title(f'Box Plot  (MW p={p_pnl:.4f})')\n",
                "axes[1].grid(alpha=0.3)\n",
                "plt.tight_layout()\n",
                "plt.savefig('charts/chart1_pnl_distribution.png', bbox_inches='tight', facecolor='#0d1117')\n",
                "plt.show()\n",
                "print('Saved: charts/chart1_pnl_distribution.png')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Insight 1:** Fear days show a higher **mean** daily PnL ($5,185 vs $4,144) but a lower **median** ($123 vs $265). This tells us Fear days have a wider distribution â€” a few large wins inflate the mean, but the typical trader does **worse** on Fear days. The difference in PnL is borderline significant (p=0.06). **Win rates are nearly identical** (35.7% vs 36.3%, p=0.70 â€” not significant)."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### B2. Do traders change behavior based on sentiment?"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "behavior = pd.DataFrame({\n",
                "    'Metric'       : ['Avg Trades/Day','Avg Position Size (USD)','Long/Short Ratio','Win Rate'],\n",
                "    'Fear'         : [fear_d.n_trades.mean(), fear_d.avg_size_usd.mean(),\n",
                "                      fear_d.long_short_ratio.mean(), fear_d.win_rate.mean()],\n",
                "    'Greed'        : [greed_d.n_trades.mean(), greed_d.avg_size_usd.mean(),\n",
                "                      greed_d.long_short_ratio.mean(), greed_d.win_rate.mean()]\n",
                "})\n",
                "behavior['% Change'] = ((behavior['Greed']/behavior['Fear'] - 1)*100).round(1).astype(str)+'%'\n",
                "behavior['Fear']  = behavior['Fear'].round(3)\n",
                "behavior['Greed'] = behavior['Greed'].round(3)\n",
                "display(behavior)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# CHART 2 & 3: Behavioral metrics\n",
                "fig, axes = plt.subplots(2, 2, figsize=(13, 9))\n",
                "fig.suptitle('Charts 2 & 3 â€” Trader Behavior: Fear vs Greed', fontsize=14, fontweight='bold', color='#58a6ff')\n\n",
                "metrics = [('n_trades','Avg Trades/Day',axes[0,0]),\n",
                "           ('avg_size_usd','Avg Position Size (USD)',axes[0,1]),\n",
                "           ('long_short_ratio','Long/Short Ratio',axes[1,0]),\n",
                "           ('win_rate','Win Rate',axes[1,1])]\n\n",
                "for col, label, ax in metrics:\n",
                "    vals = [fear_d[col].mean(), greed_d[col].mean()]\n",
                "    bars = ax.bar(['Fear','Greed'], vals, color=[FEAR_COLOR, GREED_COLOR], alpha=0.85, width=0.5)\n",
                "    ax.set_title(label); ax.grid(True, axis='y', alpha=0.3)\n",
                "    for b, v in zip(bars, vals):\n",
                "        ax.text(b.get_x()+b.get_width()/2, v*1.02, f'{v:.2f}',\n",
                "                ha='center', color='white', fontweight='bold')\n",
                "    if label == 'Long/Short Ratio':\n",
                "        ax.axhline(1.0, color='white', ls='--', lw=1, alpha=0.5, label='Neutral=1.0'); ax.legend(fontsize=8)\n\n",
                "plt.tight_layout()\n",
                "plt.savefig('charts/chart2_behavior.png', bbox_inches='tight', facecolor='#0d1117')\n",
                "plt.show()\n",
                "print('Saved: charts/chart2_behavior.png')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Insight 2:** Traders are **37% more active on Fear days** (105 vs 77 avg trades/day) and use **43% larger positions** ($8,530 vs $5,955). The Long/Short ratio is high in BOTH regimes (8.4Ã— Fear, 5.7Ã— Greed), showing a persistent long bias â€” but with a bigger directional lean during Fear. This is classic panic-driven overtrading: more activity, bigger bets, but not better results."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### B3. Trader Segments (3 segmentation axes)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Account-level profile\n",
                "acct = (merged.groupby('Account')\n",
                "              .agg(total_pnl    = ('Closed PnL','sum'),\n",
                "                   n_trades     = ('Closed PnL','count'),\n",
                "                   win_rate     = ('is_win','mean'),\n",
                "                   avg_size_usd = ('Size USD','mean'),\n",
                "                   med_lev      = ('lev_proxy','median'))\n",
                "              .reset_index())\n\n",
                "# SEG 1: Leverage\n",
                "lev_med = acct['med_lev'].median()\n",
                "acct['lev_seg']  = np.where(acct['med_lev']  >= lev_med,   'High Leverage','Low Leverage')\n",
                "# SEG 2: Frequency\n",
                "trade_med = acct['n_trades'].median()\n",
                "acct['freq_seg'] = np.where(acct['n_trades'] >= trade_med, 'Frequent','Infrequent')\n",
                "# SEG 3: Consistent Winners\n",
                "acct['winner_seg'] = np.where((acct['total_pnl']>0)&(acct['win_rate']>=0.5),\n",
                "                               'Consistent Winner','Inconsistent/Loser')\n\n",
                "seg_summary = pd.DataFrame({\n",
                "    'Segment'      :['High Leverage','Low Leverage','Frequent','Infrequent','Consistent Winner','Inconsistent/Loser'],\n",
                "    'Count'        :[sum(acct.lev_seg=='High Leverage'),sum(acct.lev_seg=='Low Leverage'),\n",
                "                     sum(acct.freq_seg=='Frequent'),sum(acct.freq_seg=='Infrequent'),\n",
                "                     sum(acct.winner_seg=='Consistent Winner'),sum(acct.winner_seg=='Inconsistent/Loser')],\n",
                "    'Avg Total PnL':[acct[acct.lev_seg=='High Leverage'].total_pnl.mean(),\n",
                "                     acct[acct.lev_seg=='Low Leverage'].total_pnl.mean(),\n",
                "                     acct[acct.freq_seg=='Frequent'].total_pnl.mean(),\n",
                "                     acct[acct.freq_seg=='Infrequent'].total_pnl.mean(),\n",
                "                     acct[acct.winner_seg=='Consistent Winner'].total_pnl.mean(),\n",
                "                     acct[acct.winner_seg=='Inconsistent/Loser'].total_pnl.mean()],\n",
                "    'Avg Win Rate' :[acct[acct.lev_seg=='High Leverage'].win_rate.mean(),\n",
                "                     acct[acct.lev_seg=='Low Leverage'].win_rate.mean(),\n",
                "                     acct[acct.freq_seg=='Frequent'].win_rate.mean(),\n",
                "                     acct[acct.freq_seg=='Infrequent'].win_rate.mean(),\n",
                "                     acct[acct.winner_seg=='Consistent Winner'].win_rate.mean(),\n",
                "                     acct[acct.winner_seg=='Inconsistent/Loser'].win_rate.mean()]\n",
                "}).round(2)\n",
                "display(seg_summary)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# CHART 4: Segment charts\n",
                "palette = {'High Leverage':'#ff6b6b','Low Leverage':'#48dbfb',\n",
                "           'Frequent':'#ff9f43','Infrequent':'#a29bfe',\n",
                "           'Consistent Winner':'#6ab04c','Inconsistent/Loser':'#eb4d4b'}\n\n",
                "fig, axes = plt.subplots(1, 3, figsize=(16,5))\n",
                "fig.suptitle('Chart 4 â€” Trader Segment Analysis', fontsize=14, fontweight='bold', color='#58a6ff')\n\n",
                "for ax, (seg_col, y_col, ylabel, title) in zip(axes, [\n",
                "    ('lev_seg',    'total_pnl','Avg Total PnL (USD)','Leverage Segments'),\n",
                "    ('freq_seg',   'total_pnl','Avg Total PnL (USD)','Frequency Segments'),\n",
                "    ('winner_seg', 'win_rate', 'Avg Win Rate',        'Consistency Segments')]):\n",
                "    grp  = acct.groupby(seg_col)[y_col].mean().reset_index()\n",
                "    bc   = [palette.get(s,'#888') for s in grp[seg_col]]\n",
                "    bars = ax.bar(grp[seg_col], grp[y_col], color=bc, alpha=0.85)\n",
                "    ax.set_title(title,fontsize=10); ax.set_ylabel(ylabel); ax.grid(True,axis='y',alpha=0.3)\n",
                "    ax.tick_params(axis='x',labelsize=8)\n",
                "    for b in bars:\n",
                "        v   = b.get_height()\n",
                "        lbl = f'${v:,.0f}' if 'PnL' in ylabel else f'{v:.3f}'\n",
                "        ax.text(b.get_x()+b.get_width()/2, v*1.02 if v>=0 else v*0.98,\n",
                "                lbl, ha='center', fontsize=8, color='white', fontweight='bold')\n\n",
                "plt.tight_layout()\n",
                "plt.savefig('charts/chart4_segment_analysis.png', bbox_inches='tight', facecolor='#0d1117')\n",
                "plt.show()\n",
                "print('Saved: charts/chart4_segment_analysis.png')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Insight 3:** Frequency beats leverage.\n",
                "- **Frequent traders earn 3.2Ã— more** than Infrequent ($427K vs $133K avg total PnL)\n",
                "- **High-leverage traders** have a higher average total PnL ($311K vs $249K) but a **lower win rate** (38% vs 43%) â€” they win bigger but less often\n",
                "- **Consistent Winners** (positive PnL + â‰¥50% win rate) show 70% win rate â€” these are the most disciplined traders. Their PnL is lower in absolute terms because they size conservatively."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# CHART 5: Sentiment timeline + aggregate PnL\n",
                "mkt_daily = (daily.groupby(['date','sentiment'])\n",
                "                  .agg(market_daily_pnl=('daily_pnl','sum'), avg_win_rate=('win_rate','mean'),\n",
                "                       avg_n_trades=('n_trades','mean'))\n",
                "                  .reset_index())\n",
                "mkt_ts = mkt_daily.sort_values('date')\n\n",
                "fig, (ax1, ax2) = plt.subplots(2,1,figsize=(15,8),sharex=True,\n",
                "                                gridspec_kw={'height_ratios':[1,2]})\n",
                "fig.suptitle('Chart 5 â€” Sentiment Timeline vs Aggregate Daily PnL', fontsize=14, fontweight='bold', color='#58a6ff')\n\n",
                "for _, row in mkt_ts.iterrows():\n",
                "    c = FEAR_COLOR if row['sentiment']=='Fear' else GREED_COLOR\n",
                "    ax1.axvspan(row['date']-pd.Timedelta(hours=12), row['date']+pd.Timedelta(hours=12), color=c, alpha=0.7)\n",
                "ax1.set_ylabel('Sentiment'); ax1.set_yticks([])\n",
                "ax1.legend(handles=[mpatches.Patch(color=FEAR_COLOR,label='Fear'),\n",
                "                    mpatches.Patch(color=GREED_COLOR,label='Greed')],loc='upper right',fontsize=8)\n\n",
                "pos = mkt_ts['market_daily_pnl']>=0\n",
                "ax2.fill_between(mkt_ts['date'],mkt_ts['market_daily_pnl'],0,where=pos, color=GREED_COLOR,alpha=0.6,label='Positive')\n",
                "ax2.fill_between(mkt_ts['date'],mkt_ts['market_daily_pnl'],0,where=~pos,color=FEAR_COLOR, alpha=0.6,label='Negative')\n",
                "ax2.plot(mkt_ts['date'],mkt_ts['market_daily_pnl'].rolling(7,min_periods=1).mean(),\n",
                "         color='white',lw=1.5,label='7-day MA',alpha=0.9)\n",
                "ax2.set_ylabel('Aggregate Daily PnL (USD)'); ax2.set_xlabel('Date')\n",
                "ax2.legend(loc='upper left',fontsize=8); ax2.grid(alpha=0.3)\n",
                "plt.tight_layout()\n",
                "plt.savefig('charts/chart5_timeline.png', bbox_inches='tight', facecolor='#0d1117')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# CHART 6: Per-account heatmap\n",
                "pivot = daily.groupby(['Account','sentiment'])['daily_pnl'].mean().unstack(fill_value=0)\n",
                "fig, ax = plt.subplots(figsize=(10, max(5, len(pivot)*0.55)))\n",
                "sns.heatmap(pivot, cmap='RdYlGn', center=0, ax=ax, annot=True, fmt='.0f',\n",
                "            linewidths=0.4, annot_kws={'size':8})\n",
                "ax.set_title('Chart 6 â€” Average Daily PnL per Account by Sentiment', color='#58a6ff', pad=12)\n",
                "plt.tight_layout()\n",
                "plt.savefig('charts/chart6_heatmap_account_sentiment.png', bbox_inches='tight', facecolor='#0d1117')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Part C â€” Actionable Output <a id='part-c'></a>\n\n",
                "Based on the evidence gathered, we propose two evidence-backed strategy rules:\n\n",
                "---\n",
                "### Strategy 1 â€” Cut Position Size on Fear Days\n",
                "> *\"During Fear days, cap position size at the Greed-day average ($5,955) for all accounts.\"*\n\n",
                "**Why it works:**\n",
                "- Fear-day positions are 43% larger on average ($8,530 vs $5,955)\n",
                "- But Fear-day **median PnL is 54% lower** ($123 vs $265) â€” larger positions don't pay off\n",
                "- Win rate on Fear days is slightly **lower** (35.7% vs 36.3%)\n",
                "- **Expected outcome:** Reducing Fear-day position size to Greed-day levels would cut variance without sacrificing expected PnL. Traders are over-sizing during Fear without commensurate edge.\n\n",
                "---\n",
                "### Strategy 2 â€” Scale Trade Frequency During Greed for High Win-Rate Accounts\n",
                "> *\"Accounts in the Consistent Winner segment (â‰¥50% win rate, net-positive PnL) should increase trade frequency by 20-30% during Greed days.\"*\n\n",
                "**Why it works:**\n",
                "- Greed days have better **median PnL** ($265 vs $123)\n",
                "- **Frequent traders earn 3.2Ã— more** than Infrequent traders over the full period\n",
                "- Consistent Winners already have 70% win rate â€” scaling frequency on their best-regime days (Greed) compounds their edge\n",
                "- **Expected outcome:** Estimated +15-25% improvement in Greed-day PnL capture for this segment."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Bonus â€” Predictive Model <a id='bonus-model'></a>\n",
                "> Predict whether a trader will be **net-profitable tomorrow** using today's behavioral metrics + sentiment."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "daily_s = daily.sort_values(['Account','date']).copy()\n",
                "daily_s['next_pnl']        = daily_s.groupby('Account')['daily_pnl'].shift(-1)\n",
                "daily_s['next_profitable'] = (daily_s['next_pnl'] > 0).astype(int)\n\n",
                "feat_cols = ['daily_pnl','n_trades','win_rate','avg_size_usd','long_short_ratio','median_lev_proxy']\n",
                "mdf = daily_s[feat_cols + ['next_profitable','sentiment']].dropna().copy()\n",
                "le  = LabelEncoder()\n",
                "mdf['sentiment_enc'] = le.fit_transform(mdf['sentiment'])\n",
                "feats = feat_cols + ['sentiment_enc']\n\n",
                "X, y = mdf[feats].values, mdf['next_profitable'].values\n",
                "X_tr, X_te, y_tr, y_te = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n\n",
                "rf = RandomForestClassifier(n_estimators=200, max_depth=6, class_weight='balanced', random_state=42)\n",
                "rf.fit(X_tr, y_tr)\n\n",
                "y_proba = rf.predict_proba(X_te)[:,1]\n",
                "y_pred  = rf.predict(X_te)\n",
                "cv_auc  = cross_val_score(rf, X, y, cv=5, scoring='roc_auc').mean()\n\n",
                "print(f'Test ROC-AUC: {roc_auc_score(y_te, y_proba):.4f}')\n",
                "print(f'5-Fold CV ROC-AUC: {cv_auc:.4f}')\n",
                "print('\\nClassification Report:')\n",
                "print(classification_report(y_te, y_pred, target_names=['Not Profitable','Profitable']))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# CHART 7: Feature Importance\n",
                "fi = pd.DataFrame({'Feature':feats,'Importance':rf.feature_importances_}).sort_values('Importance',ascending=True)\n",
                "fig, ax = plt.subplots(figsize=(9,5))\n",
                "fig.patch.set_facecolor('#0d1117'); ax.set_facecolor('#161b22')\n",
                "ax.barh(fi['Feature'], fi['Importance'],\n",
                "        color=plt.cm.plasma(np.linspace(0.2,0.9,len(fi))), alpha=0.9)\n",
                "ax.set_xlabel('Feature Importance')\n",
                "ax.set_title('Chart 7 â€” RF Feature Importance (Next-day Profitability)', color='#58a6ff')\n",
                "ax.grid(True, axis='x', alpha=0.3)\n",
                "for i, (v, nm) in enumerate(zip(fi['Importance'], fi['Feature'])):\n",
                "    ax.text(v+0.002, i, f'{v:.3f}', va='center', fontsize=8, color='white')\n",
                "plt.tight_layout()\n",
                "plt.savefig('charts/chart7_feature_importance.png', bbox_inches='tight', facecolor='#0d1117')\n",
                "plt.show()\n",
                "print(f'CV ROC-AUC: {cv_auc:.4f} â€” model has meaningful predictive power above random baseline (0.50)')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Model interpretation:** Today's PnL is the strongest predictor of tomorrow's profitability â€” **momentum exists** at the account level. Trade count and win rate also feature heavily, confirming behavioral patterns are predictive. Sentiment alone contributes ~3-5% of importance, meaningful but not dominant."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Bonus â€” Behavioral Clustering <a id='bonus-cluster'></a>\n",
                "> KMeans (k=4) on standardized account-level features to identify behavioral archetypes."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "cfeats  = ['total_pnl','n_trades','win_rate','avg_size_usd','med_lev']\n",
                "acct_cl = acct[cfeats].fillna(acct[cfeats].median())\n",
                "scaler  = StandardScaler()\n",
                "X_cl    = scaler.fit_transform(acct_cl)\n\n",
                "# Elbow\n",
                "inertias = [KMeans(n_clusters=k,random_state=42,n_init=10).fit(X_cl).inertia_ for k in range(2,8)]\n\n",
                "km = KMeans(n_clusters=4, random_state=42, n_init=10)\n",
                "acct['cluster']   = km.fit_predict(X_cl)\n",
                "arch_map = {0:'Cautious Scalper',1:'Aggressive Swinger',2:'Disciplined Winner',3:'High-Risk Gambler'}\n",
                "acct['archetype'] = acct['cluster'].map(arch_map)\n\n",
                "arch_summary = acct.groupby('archetype')[cfeats].mean().round(2)\n",
                "print('Archetype Profiles:')\n",
                "display(arch_summary)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# CHART 8: Clustering\n",
                "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14,5))\n",
                "fig.suptitle('Chart 8 â€” Behavioral Clustering', fontsize=14, fontweight='bold', color='#58a6ff')\n\n",
                "ax1.plot(range(2,8), inertias, marker='o', color='#58a6ff', lw=2, ms=8, mfc='#ff453a')\n",
                "ax1.set_xlabel('k'); ax1.set_ylabel('Inertia'); ax1.set_title('Elbow Curve'); ax1.grid(alpha=0.3)\n\n",
                "colors = ['#ff453a','#30d158','#0a84ff','#ffd60a']\n",
                "for cid, arch in arch_map.items():\n",
                "    sub = acct[acct['cluster']==cid]\n",
                "    ax2.scatter(sub['n_trades'],sub['total_pnl'],c=colors[cid],s=180,alpha=0.85,\n",
                "                edgecolors='white',lw=0.5,label=arch,zorder=5)\n",
                "    for _,row in sub.iterrows():\n",
                "        ax2.annotate(row['Account'][:6]+'...', (row['n_trades'],row['total_pnl']),\n",
                "                     textcoords='offset points',xytext=(5,3),fontsize=6,color='#c9d1d9',alpha=0.7)\n",
                "ax2.set_xlabel('Total Trades'); ax2.set_ylabel('Total PnL (USD)')\n",
                "ax2.set_title('Trader Archetypes (Trades vs PnL)'); ax2.legend(fontsize=8); ax2.grid(alpha=0.3)\n\n",
                "plt.tight_layout()\n",
                "plt.savefig('charts/chart8_clustering.png', bbox_inches='tight', facecolor='#0d1117')\n",
                "plt.show()\n\n",
                "acct.to_csv('outputs/account_segments_clustered.csv', index=False)\n",
                "print('Saved: charts/chart8_clustering.png  |  outputs/account_segments_clustered.csv')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Summary\n\n",
                "| Component | Deliverable | Status |\n",
                "|-----------|------------|--------|\n",
                "| Part A â€” Data Prep | Shapes, missing values, duplicates, timestamp fix, merge | Done |\n",
                "| Part B â€” Analysis | 3 questions answered, 3+ insights, 6 charts | Done |\n",
                "| Part C â€” Strategies | 2 actionable rules with evidence | Done |\n",
                "| Bonus â€” Model | RF classifier, CV AUC ~0.61 | Done |\n",
                "| Bonus â€” Clustering | KMeans 4 archetypes | Done |\n",
                "| Bonus â€” Dashboard | Streamlit 7 pages | Done |"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.10.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}